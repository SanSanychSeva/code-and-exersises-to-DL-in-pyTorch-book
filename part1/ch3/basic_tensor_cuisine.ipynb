{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6a4670f-65c5-46c7-bb86-aa106182348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45108a1-2be5-41be-86cf-0d946b3743ec",
   "metadata": {},
   "source": [
    "# e.g.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470d9bac-8ae9-433a-afdd-40e7899a619b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3), torch.zeros(3)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93fd1e0-b3e6-4dd9-89fb-118dae0eb009",
   "metadata": {},
   "source": [
    "# e.g.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf2c776b-b668-4d15-98b2-a947b86fa340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle_points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "triangle_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3653f41-3f96-4c62-9e18-8e8898c84141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596f3fd9-a9d6-4300-beee-22956e8b117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle_points[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fa9ef1-ea57-4213-b582-1bbb00e17e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle_points[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50494a77-80ca-4208-8d74-e3a08532fb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triangle_points[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a2e3f3-fc55-4ab4-82fe-4f2e7b29d8be",
   "metadata": {},
   "source": [
    "# e.g.3 - разделяет пробелами при выводе лучше чем numpy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4e066b-3f2a-4d08-8fe1-8ed6f652448d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e750cd-4a31-4b8a-9668-1ee731fc7769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(3,2,4,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d53833-9091-49b7-aeb2-a8405a818427",
   "metadata": {},
   "source": [
    "# семантически именованные измерения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdf0dfd7-5b0b-4644-b267-e5c24fd5392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.randn(3, 5, 5)                     # форма [каналы (цветовые), строки, столбцы]\n",
    "batch_t = torch.randn(100, 3, 5, 5)              # форма [батч, каналы, строки, столбцы]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722]) # форма [вероятности классов]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eed6acae-37fe-4538-8a6e-7896c32f822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17505/2371314847.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /pytorch/c10/core/TensorImpl.h:1939.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d005f6-988a-40ca-aba6-1b0995549ff2",
   "metadata": {},
   "source": [
    "## обычно семантический порядок одинаков с конца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69600f20-e96f-4fed-bae1-f6d9a1fb5a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([100, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "\n",
    "print(\"img named:\", img_named.shape, img_named.names)\n",
    "print(\"batch named:\", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9d0da-281d-49da-9245-c2835c9f62e0",
   "metadata": {},
   "source": [
    "### но одномерные измерения опускаются, имена позволяют их восстановить по семантике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3390131-e201-4980-b3d3-cd9ecd20c130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights aligned: torch.Size([3, 1, 1]) ('channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    "\n",
    "print('weights aligned:', weights_aligned.shape, weights_aligned.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd6cc9-1690-4ed1-b5d2-7e8805c8ebf4",
   "metadata": {},
   "source": [
    "### теперь могу замешать цветовые каналы в оттенки серого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "613b9267-b344-4eb2-87c7-d03bc2d6f983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ca322df-3f43-4f3e-ad54-6a4a544b36f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_naive = img_named.mean('channels')\n",
    "gray_naive.shape, gray_naive.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "413b2678-dad7-4d01-b8cc-9509f4492f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), ('rows', 'columns'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_naive = img_named.mean(-3)\n",
    "gray_naive.shape, gray_naive.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b6179d8-dd73-4076-ac52-023fa986de42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), (None, None))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae858cce-24cb-47c2-b033-cd8dc6d25c4f",
   "metadata": {},
   "source": [
    "# PyTorch позволяет перемножать объекты одинаковой формы: \n",
    "## либо когда один из них имеет размер 1 по заданному измерению (тогда по этому измерению идет как умножение на скаляр)\n",
    "## либо PyTorch автоматически добавляет (делает broadcasting на недостающие измерения) в начало списка индексов новые измерения размером 1 (тогда по ним тоже как умножение на скаляр)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c9e5f2d-8106-4f6c-bbc3-a58676ca04b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytest = torch.tensor([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9],\n",
    "        [10,11,12]\n",
    "    ],\n",
    "    [\n",
    "        [13,14,15],\n",
    "        [16,17,18],\n",
    "        [19,20,21],\n",
    "        [22,23,24]\n",
    "    ]\n",
    "])\n",
    "mytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a58d06d7-9a66-4a99-a9ca-e5aac4d5f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_2 = torch.tensor([1,2])\n",
    "weights_3 = torch.tensor([1,2,3])\n",
    "weights_4 = torch.tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de310498-37d2-4725-a371-077cc9f65c7a",
   "metadata": {},
   "source": [
    "### для таких пройдет только свертка по последнему измерению - при совпадении размерности по нему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e729881-901a-473f-8fdd-894cf580c286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR FYI: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mytest * weights_2\n",
    "except BaseException as err_message:\n",
    "    print('\\nERROR FYI:', err_message,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d664891e-daed-439c-a81c-c683c8ebcc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Это пройдет равносильно приписыванию всех измерений слева с размерностью 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  4,  9],\n",
       "         [ 4, 10, 18],\n",
       "         [ 7, 16, 27],\n",
       "         [10, 22, 36]],\n",
       "\n",
       "        [[13, 28, 45],\n",
       "         [16, 34, 54],\n",
       "         [19, 40, 63],\n",
       "         [22, 46, 72]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nЭто пройдет равносильно приписыванию всех измерений слева с размерностью 1:')\n",
    "mytest * weights_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c00ecb6-4674-4b07-ae42-08ec05bbb3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 1, 3]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_3.shape, weights_3.unsqueeze(0).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32df51fc-f188-4b88-a90d-43212a83d408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  4,  9],\n",
       "         [ 4, 10, 18],\n",
       "         [ 7, 16, 27],\n",
       "         [10, 22, 36]],\n",
       "\n",
       "        [[13, 28, 45],\n",
       "         [16, 34, 54],\n",
       "         [19, 40, 63],\n",
       "         [22, 46, 72]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytest * (weights_3.unsqueeze(0).unsqueeze(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aebf7d66-305c-475f-aace-95ec3cd62a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR FYI: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mytest * weights_4\n",
    "except BaseException as err_message:\n",
    "    print('\\nERROR FYI:', err_message,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b682631-ede4-41d1-aade-02715fab0447",
   "metadata": {},
   "source": [
    "### чтобы свернуть, надо сдвинуть свертываемое измерение на нужную позицию в списке индексов (либо использовать именование индексов и свертывать по имени индекса)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28202e-f5d6-420e-9582-e95a43152a92",
   "metadata": {},
   "source": [
    "#### пример 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ef69686-84d6-4d2e-a2f8-21ca2d3e4619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4]), torch.Size([4, 1]), torch.Size([1, 4, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_4.shape, weights_4.unsqueeze(-1).shape, weights_4.unsqueeze(-1).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ec991d0-1b5c-4dab-a4ea-5f06fe20197a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 3]), torch.Size([2, 4, 3]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mytest * (weights_4.unsqueeze(-1))).shape, (mytest * (weights_4.unsqueeze(-1).unsqueeze(0))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45fcfae2-6c62-4d8d-86e4-df327e5ba1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 8, 10, 12],\n",
       "         [21, 24, 27],\n",
       "         [40, 44, 48]],\n",
       "\n",
       "        [[13, 14, 15],\n",
       "         [32, 34, 36],\n",
       "         [57, 60, 63],\n",
       "         [88, 92, 96]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mytest * (weights_4.unsqueeze(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf86b821-99df-4fc5-aeaa-e2bbf0246921",
   "metadata": {},
   "source": [
    "#### пример 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2671bc8e-0a0f-40be-a2b8-7c75389e3e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([2, 1, 1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_2.shape, weights_2.unsqueeze(-1).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "585842b0-951a-427c-9b14-39e4e8529978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mytest * (weights_2.unsqueeze(-1).unsqueeze(-1))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc4f8c2d-a884-42f6-b4cb-5e81797264c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12]],\n",
       "\n",
       "        [[26, 28, 30],\n",
       "         [32, 34, 36],\n",
       "         [38, 40, 42],\n",
       "         [44, 46, 48]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytest * (weights_2.unsqueeze(-1).unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26e5a1-7fb7-4153-b85a-f55bf43f2a48",
   "metadata": {},
   "source": [
    "#### итак, справа измерения добавляем руками - так как это меняет их семантику, а слева добавляются автоматически - копируя семантику из тензора с большим кол-вом измерений (если именовать измерения, то и справа сможет добавиться автоматом - так как семантика обозначена в имени!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9959b965-9728-4077-b9d2-0f9bd062a908",
   "metadata": {},
   "source": [
    "# в numpy есть функция `einsum()` свертки по промежуточным индексам со строковым описанием позиций индексов, которая также перенесена в PyTorch https://rockt.github.io/2018/04/30/einsum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34df7cb6-46b8-46f1-9ca8-e45ddbc80bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([3, 5, 5]), torch.Size([100, 3, 5, 5]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape, img_t.shape, batch_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f33e5263-df86-4f77-851f-bcfbf70fba42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([100, 5, 5]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_weighted_fancy = torch.einsum('chw,c->hw', img_t, weights)           # свертка по индексу с\n",
    "batch_gray_weighted_fancy = torch.einsum('bchw,c->bhw', batch_t, weights)     # свертка по индексу с\n",
    "\n",
    "img_gray_weighted_fancy.shape, batch_gray_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29df45-4f36-4c53-a727-c11f90f15166",
   "metadata": {},
   "source": [
    "## `...` означает несколько индексов - так где это однозначно восстановимо:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef3239e7-6bbc-4fa7-aa9c-a94edf1e9e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5, 5]), torch.Size([3, 5, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_named.shape, img_named[..., :3].shape, weights_named.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb2a01f8-7588-4dc3-bea0-0237f98b907d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('channels', 'rows', 'columns'),\n",
       " ('channels', 'rows', 'columns'),\n",
       " ('channels',))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_named.names, img_named[..., :3].names, weights_named.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ca48f-ff70-412d-8e66-d330f31e5786",
   "metadata": {},
   "source": [
    "### поэтому если мы не уверены, сколько еще слева добавится измерений, можно их не специфицировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "896313bd-a799-4c02-acc9-15ef7e53fbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([100, 5, 5]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)         # свертка по индуксу в позиции с (третий справа)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)     # свертка по индуксу в позиции с (третий справа)\n",
    "\n",
    "img_gray_weighted_fancy.shape, batch_gray_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a21b1a-2707-4bef-ad4e-ab26730d640e",
   "metadata": {},
   "source": [
    "**получили то же самое, как при полной спецификации списка индексов выше**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e2d61-0c0f-4cfd-b620-8849b84b3241",
   "metadata": {},
   "source": [
    "# Эйнштейновская свертка работает как в физике:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c45824-9b9e-403a-82f4-ea8fa03a2894",
   "metadata": {},
   "source": [
    "$T_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48d01c9b-42ff-4336-be10-d84dfa0fa983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_ij = np.array([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "T_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c77fdb-4ccc-40a4-a153-e5bc4f826d57",
   "metadata": {},
   "source": [
    "$T^T = T_{ji}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94515d1d-c25f-4949-bec9-ff6f9587dc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ij->ji',T_ij)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d8aa34-0dd0-4b5d-bf5f-25c066747b14",
   "metadata": {},
   "source": [
    "$\\sum_j T_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbb182fd-1589-4092-bc75-e96af1a0525f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ij->i',T_ij)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb49fa8-3348-41bc-b334-c92c7f86946a",
   "metadata": {},
   "source": [
    "$Trace(T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47823997-64f6-4991-83c7-092f11467300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 4]), np.int64(5))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ii->i',T_ij), np.einsum('ii->i',T_ij).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7f814-7677-4770-a9cc-67a661f77334",
   "metadata": {},
   "source": [
    "# ХРАНИЛИЩЕ vs ИНДЕКСАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd3d82e1-82ae-46fc-a4f3-2599309a394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17505/2923139482.py:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  points.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 4.0\n",
       " 1.0\n",
       " 5.0\n",
       " 3.0\n",
       " 2.0\n",
       " 1.0\n",
       "[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101e680-3c30-4fd8-9a73-fb05c382f33f",
   "metadata": {},
   "source": [
    "## попробуем совет из ворнинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7c6038b-e507-44cb-833a-cbe9a41b1f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 0\n",
       " 128\n",
       " 64\n",
       " 0\n",
       " 0\n",
       " 128\n",
       " 63\n",
       " 0\n",
       " 0\n",
       " 160\n",
       " 64\n",
       " 0\n",
       " 0\n",
       " 64\n",
       " 64\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 64\n",
       " 0\n",
       " 0\n",
       " 128\n",
       " 63\n",
       "[torch.storage.UntypedStorage(device=cpu) of size 24]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.untyped_storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e4f01-1774-4176-9310-3f45eee29788",
   "metadata": {},
   "source": [
    "## г.м., может в бинарном будет виден смысл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8489b658-3fed-4e54-95a6-824c0696e23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000\n",
      "00000000\n",
      "10000000\n",
      "01000000\n",
      "----------\n",
      "00000000\n",
      "00000000\n",
      "10000000\n",
      "00111111\n",
      "----------\n",
      "00000000\n",
      "00000000\n",
      "10100000\n",
      "01000000\n",
      "----------\n",
      "00000000\n",
      "00000000\n",
      "01000000\n",
      "01000000\n",
      "----------\n",
      "00000000\n",
      "00000000\n",
      "00000000\n",
      "01000000\n",
      "----------\n",
      "00000000\n",
      "00000000\n",
      "10000000\n",
      "00111111\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for B in points.untyped_storage():\n",
    "    count += 1\n",
    "    print(bin(B).split('b')[1].rjust(8,'0'))\n",
    "    if count % 4 == 0:\n",
    "        print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42120a9c-0847-48b6-a9bc-359c2d98b0b8",
   "metadata": {},
   "source": [
    "**хз все равно! Видно только, что второй и последний элементы совпадают**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6eadec-c569-4ea3-a302-682eecc33664",
   "metadata": {},
   "source": [
    "## любуемся на офсеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "278829f8-9b3e-46f8-a4bd-6bc364284003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5544ce0b-99a2-4398-9bf4-4f7fba3b3429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[el for el in raw] for raw in points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8e13154-2a63-43a8-af74-cf6a0ab5cc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[el.storage_offset() for el in raw] for raw in points])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f20a5a-2256-45fd-a2f6-d96cf1339acc",
   "metadata": {},
   "source": [
    "## любуемся на размеры (совпадает с `shape`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d6290cb-e231-46ed-8f4c-81ccccf1e0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[torch.Size([]), torch.Size([])],\n",
       " [torch.Size([]), torch.Size([])],\n",
       " [torch.Size([]), torch.Size([])]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[el.size() for el in raw] for raw in points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e18f4446-b436-4123-b295-3cabd3105eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([2]), torch.Size([2]), torch.Size([2])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[raw.size() for raw in points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77955368-d27a-419d-a63c-82693a6cd17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896f6d4-cb37-4f7a-bece-2a61426c19d3",
   "metadata": {},
   "source": [
    "## любуемся на шаги (многомерные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bec00f48-56e4-4fe5-9a79-66f5764d38bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202b458-c844-45a4-9613-224ff5f0e091",
   "metadata": {},
   "source": [
    "# копирование при срезах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49e93205-cfc9-49fd-847e-f4a2a2f817e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "311ab9b2-4354-4bfd-836a-e3c097058cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_row = points[1]\n",
    "points_row[0] = 10\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f486e8df-b971-47fd-8f1c-6372bcc1ac82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_row = points[1].clone()    # смена хранилища\n",
    "points_row[0] = 5\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671b5171-6fb1-45dc-a6b7-d24fc1714901",
   "metadata": {},
   "source": [
    "# транспонирование и непрерывность тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0c4e10e-4eb8-48af-a89c-b5c8267bc4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4., 10.,  2.],\n",
       "        [ 1.,  3.,  1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09e85309-3342-4066-8461-4a77a05e9772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.t().stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5ac3375-0d45-4bbd-9815-5291e62cdd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4., 10.,  2.],\n",
       "        [ 1.,  3.,  1.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t().clone()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88796763-e16f-4249-8253-ad40a9c4e02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "633093e7-ca64-403c-9d88-fed245df0662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2aa34ec-6648-4ac5-96a7-38e59f683627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.t().is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a8a4459-3fb9-4cde-af6c-5247484d11ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4a762-952f-4f18-9dff-de6017c5d628",
   "metadata": {},
   "source": [
    "## как же вернуть непрерывность индексации транспонированному тензору (некоторые тензорные операции того требуют!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c4fca32-6ebe-4537-80b2-0bec8d978018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t = points.t().contiguous()\n",
    "points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c5e5dfc-715c-46db-a58f-16f610a3ea2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4., 10.,  2.],\n",
       "        [ 1.,  3.,  1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3fde2-5b37-4a8b-bc69-493a3d197054",
   "metadata": {},
   "source": [
    "**внешне все одинаково**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a130e199-3836-492e-9254-c40351f973d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1), (3, 1))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride() , points_t.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae40eb-8b91-491e-b08b-3d3119d0b6bb",
   "metadata": {},
   "source": [
    "# использование GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c51b4f5-d662-4016-96d9-6cee62b38f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3773ecce-1448-484e-851a-edff68d6cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    points_gpu = points.to(device='cuda')\n",
    "except BaseException as err_message:\n",
    "    print('\\nERROR FYI:', err_message,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ddd5b5e5-0820-45c6-b942-c61ff6bb4877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c188bc59-4700-47a4-8e41-9a62894e8b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]], device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf95b9fe-1703-4251-be4d-781924b38ac2",
   "metadata": {},
   "source": [
    "# смена типов между pyTorch и Numpy - происходит при общем хранилище!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0160af97-023c-4875-8840-77cdb4fd2fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  1.],\n",
       "       [10.,  3.],\n",
       "       [ 2.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c949e25f-8d21-488e-b87b-9b3e592e510c",
   "metadata": {},
   "source": [
    "**в типе видим, что размер флотов остался торчевым**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "323b7da3-3d23-4c63-9b10-7dbb1472e607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 1.],\n",
       "       [5., 3.],\n",
       "       [2., 1.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_np = np.array([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "points_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4591af62-95d0-4ff3-9d9b-bd2b0318f553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.from_numpy(points_np)\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1075a4d5-5361-478f-a68b-b37d02bc2753",
   "metadata": {},
   "source": [
    "**NB!: а вот тут прилетел дефолтный размер флотов из numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57bd579a-922c-4a20-be8f-7ca83516ff39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_np[1,0] = 10\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcefd8e-907a-4449-ac66-bd0322f47003",
   "metadata": {},
   "source": [
    "**полезно, когда работаем с тензорами торч, но потребовалась непортированная функция нампай - можно не копировать весь тензор в объект numpy, а обратиться к нему по интерфейсу numpy и вызвать редкую функцию, а потом вернуться в объекту тензора pyTorch - в данных все будет ОК!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f26d7-e466-4430-8c97-278261db5c2c",
   "metadata": {},
   "source": [
    "# в заключение сериализация - сохранение и загрузка файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2374be82-cc19-45d4-a6da-3f8a9460995e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  1.],\n",
       "        [10.,  3.],\n",
       "        [ 2.,  1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(points, 'points.t')\n",
    "torch.load('points.t', weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f47f2-cd52-4f65-ae33-3b6393a66a5a",
   "metadata": {},
   "source": [
    "## вывод в формате HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3129b2e2-601a-4401-a57f-32780b062494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6a98b-9f1a-4bc9-9a9a-e65eefcb9f87",
   "metadata": {},
   "source": [
    "**позволяет читать таблицы в память построчно и другие фишки HDF5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a518ad-7d8f-41e4-9b60-54f12fc0ff6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
